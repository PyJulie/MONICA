{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pareto_distribution(largest_class_size, num_classes, imbalance_ratio):\n",
    "    smallest_class_size = largest_class_size / imbalance_ratio\n",
    "    \n",
    "    # Calculate the ratio factor for the geometric series\n",
    "    factor = (largest_class_size / smallest_class_size)**(1 / (num_classes - 1))\n",
    "    \n",
    "    class_instances = [round(largest_class_size / (factor**i)) for i in range(num_classes)]\n",
    "    \n",
    "    # Ensure the largest class has the exact number of instances\n",
    "    class_instances[0] = largest_class_size\n",
    "    \n",
    "    return class_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organsmnist_224.npz\n",
      "['train_images', 'train_labels', 'val_images', 'val_labels', 'test_images', 'test_labels']\n",
      "train [3464, 2004, 1556, 1148, 1132, 1119, 803, 741, 721, 630, 614]\n",
      "val [491, 280, 275, 261, 246, 213, 188, 159, 140, 104, 95]\n",
      "test [2078, 1343, 968, 811, 704, 693, 510, 445, 439, 439, 397]\n",
      "[3464, 2186, 1379, 870, 549, 346, 219, 138, 87, 55, 35]\n",
      "organamnist_224.npz\n",
      "['train_images', 'train_labels', 'val_images', 'val_labels', 'test_images', 'test_labels']\n",
      "train [6164, 3963, 3929, 3919, 3817, 3561, 3031, 1956, 1474, 1390, 1357]\n",
      "val [1033, 1033, 1009, 637, 568, 529, 511, 392, 321, 233, 225]\n",
      "test [3285, 2064, 1965, 1884, 1813, 1747, 1622, 1036, 793, 785, 784]\n",
      "[6164, 3889, 2454, 1548, 977, 616, 389, 245, 155, 98, 62]\n",
      "tissuemnist_224.npz\n",
      "['train_images', 'train_labels', 'val_images', 'val_labels', 'test_images', 'test_labels']\n",
      "train [53075, 39203, 24608, 15406, 11789, 7814, 7705, 5866]\n",
      "val [7582, 5601, 3516, 2201, 1684, 1117, 1101, 838]\n",
      "test [15165, 11201, 7031, 4402, 3369, 2233, 2202, 1677]\n",
      "[53075, 27490, 14238, 7375, 3820, 1978, 1025, 531]\n",
      "pathmnist_224.npz\n",
      "['train_images', 'train_labels', 'val_images', 'val_labels', 'test_images', 'test_labels']\n",
      "train [12885, 12182, 10401, 10360, 9509, 9401, 9366, 8006, 7886]\n",
      "val [1432, 1354, 1156, 1152, 1057, 1045, 1041, 890, 877]\n",
      "test [1338, 1233, 1035, 847, 741, 634, 592, 421, 339]\n",
      "[12885, 7246, 4075, 2291, 1289, 725, 407, 229, 129]\n",
      "bloodmnist_224.npz\n",
      "['train_images', 'train_labels', 'val_images', 'val_labels', 'test_images', 'test_labels']\n",
      "train [2330, 2181, 2026, 1643, 1085, 993, 852, 849]\n",
      "val [333, 312, 290, 235, 155, 143, 122, 122]\n",
      "test [666, 624, 579, 470, 311, 284, 244, 243]\n",
      "[2330, 1207, 625, 324, 168, 87, 45, 23]\n",
      "dermamnist_224.npz\n",
      "['train_images', 'train_labels', 'val_images', 'val_labels', 'test_images', 'test_labels']\n",
      "train [4693, 779, 769, 359, 228, 99, 80]\n",
      "val [671, 111, 110, 52, 33, 14, 12]\n",
      "test [1341, 223, 220, 103, 66, 29, 23]\n",
      "[4693, 2178, 1011, 469, 218, 101, 47]\n",
      "organcmnist_224.npz\n",
      "['train_images', 'train_labels', 'val_images', 'val_labels', 'test_images', 'test_labels']\n",
      "train [2986, 1572, 1173, 1170, 1148, 1088, 1022, 1002, 619, 600, 595]\n",
      "val [429, 352, 347, 205, 202, 191, 179, 157, 132, 102, 96]\n",
      "test [1835, 962, 828, 750, 735, 727, 557, 549, 431, 421, 421]\n",
      "[2986, 1884, 1189, 750, 473, 299, 188, 119, 75, 47, 30]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "source_dir = '/mnt/sda/julie/datasets/medmnist/npz_files/'\n",
    "dic_original_distribution = {}\n",
    "dic_pareto_distribution = {}\n",
    "dic_class_map = {}\n",
    "for npz_file in os.listdir(source_dir):\n",
    "    dataset = npz_file.split('_')[0]\n",
    "    print(npz_file)\n",
    "    npz_arrays = np.load(source_dir+npz_file)\n",
    "    print(npz_arrays.files)\n",
    "    train_labels = [x[0] for x in npz_arrays['train_labels'].tolist()]\n",
    "    val_labels = [x[0] for x in npz_arrays['val_labels'].tolist()]\n",
    "    test_labels = [x[0] for x in npz_arrays['test_labels'].tolist()]\n",
    "    distribution = Counter(train_labels).most_common()\n",
    "    dic_original_distribution[dataset] = distribution\n",
    "    val_dis = Counter(val_labels).most_common()\n",
    "    test_dis = Counter(test_labels).most_common()\n",
    "    print('train', [x[1] for x in distribution])\n",
    "    print('val', [x[1] for x in val_dis])\n",
    "    print('test', [x[1] for x in test_dis])\n",
    "    print(generate_pareto_distribution(distribution[0][1], len(distribution), 100))\n",
    "    dic_pareto_distribution[dataset] = generate_pareto_distribution(distribution[0][1], len(distribution), 100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['organsmnist', 'organamnist', 'tissuemnist', 'pathmnist', 'bloodmnist', 'dermamnist', 'organcmnist'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_original_distribution.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "target_dir = '/mnt/sda/julie/datasets/medmnist/images/'\n",
    "for npz_file in os.listdir(source_dir):\n",
    "    dataset = npz_file.split('.')[0]\n",
    "    if not os.path.exists(target_dir+dataset):\n",
    "        os.mkdir(target_dir+dataset)\n",
    "    npz_arrays = np.load(source_dir+npz_file)\n",
    "    train_images = npz_arrays['train_images']\n",
    "    train_labels = npz_arrays['train_labels']\n",
    "    val_images = npz_arrays['val_images']\n",
    "    val_labels = npz_arrays['val_labels']\n",
    "    test_images = npz_arrays['test_images']\n",
    "    test_labels = npz_arrays['test_labels']\n",
    "\n",
    "    for idx in range(train_images.shape[0]):\n",
    "        img = train_images[idx]\n",
    "        label = train_labels[idx][0]\n",
    "\n",
    "        \n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        save_name = 'train_%s_%s.jpg' %(idx, label)\n",
    "\n",
    "        cv2.imwrite('%s/%s' %(target_dir+dataset, save_name), img_rgb)\n",
    "    for idx in range(val_images.shape[0]):\n",
    "        img = val_images[idx]\n",
    "        label = val_labels[idx][0]\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        save_name = 'val_%s_%s.jpg' %(idx, label)\n",
    "\n",
    "        cv2.imwrite('%s/%s' %(target_dir+dataset, save_name), img_rgb)\n",
    "    for idx in range(test_images.shape[0]):\n",
    "        img = test_images[idx]\n",
    "        label = test_labels[idx][0]\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        save_name = 'test_%s_%s.jpg' %(idx, label)\n",
    "\n",
    "        cv2.imwrite('%s/%s' %(target_dir+dataset, save_name), img_rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tissuemnist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53075, 7814, 5866, 7375, 3820, 1978, 1025, 531]\n",
      "organcmnist\n",
      "[1148, 619, 595, 600, 473, 299, 188, 119, 75, 47, 30]\n",
      "pathmnist\n",
      "[9366, 7246, 4075, 2291, 1289, 725, 407, 229, 129]\n",
      "organamnist\n",
      "[1956, 1390, 1357, 1474, 977, 616, 389, 245, 155, 98, 62]\n",
      "bloodmnist\n",
      "[852, 1207, 625, 324, 168, 87, 45, 23]\n",
      "organsmnist\n",
      "[1148, 630, 614, 721, 549, 346, 219, 138, 87, 55, 35]\n",
      "dermamnist\n",
      "[228, 359, 769, 80, 218, 101, 47]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(1)\n",
    "source_dir = '/mnt/sda/julie/datasets/medmnist/images/'\n",
    "target_dir = '/mnt/sda/julie/projects/OpenMedLongTailed/numpy/medmnist/'\n",
    "for i, dataset in enumerate(os.listdir(source_dir)):\n",
    "    train_samples = []\n",
    "    val_samples = []\n",
    "    test_samples = []\n",
    "    dic = {}\n",
    "    dataset_name = dataset.split('_')[0]\n",
    "    print(dataset_name)\n",
    "    images = os.listdir(os.path.join(source_dir, dataset))\n",
    "    random.shuffle(images)\n",
    "    pareto_distribution = dic_pareto_distribution[dataset_name]\n",
    "    train_sample_count = [0 for i in range(len(pareto_distribution))]\n",
    "    for img in images:\n",
    "        label = int(img.split('.jpg')[0].split('_')[-1])\n",
    "        dic[img] = label\n",
    "        if img.startswith('train'):\n",
    "            if train_sample_count[label]>=pareto_distribution[label]:\n",
    "                continue\n",
    "            else:\n",
    "                train_sample_count[label]+=1\n",
    "                train_samples.append(img)\n",
    "        elif img.startswith('val'):\n",
    "            val_samples.append(img)\n",
    "        elif img.startswith('test'):\n",
    "            test_samples.append(img)\n",
    "    print(train_sample_count)\n",
    "    np.save('%s%s_train.npy' %(target_dir, dataset_name), train_samples)\n",
    "    np.save('%s%s_val.npy' %(target_dir, dataset_name), val_samples)\n",
    "    np.save('%s%s_test.npy' %(target_dir, dataset_name), test_samples)\n",
    "    np.save('%s%s_dic.npy' %(target_dir, dataset_name), dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tissuemnist\n",
      "[(0, 7582), (6, 5601), (7, 3516), (3, 2201), (4, 1684), (1, 1117), (5, 1101), (2, 838)]\n",
      "organcmnist\n",
      "[(6, 429), (8, 352), (7, 347), (10, 205), (3, 202), (0, 191), (9, 179), (5, 157), (4, 132), (1, 102), (2, 96)]\n",
      "pathmnist\n",
      "[(8, 1432), (5, 1354), (3, 1156), (2, 1152), (1, 1057), (7, 1045), (0, 1041), (4, 890), (6, 877)]\n",
      "organamnist\n",
      "[(6, 1033), (7, 1033), (8, 1009), (5, 637), (4, 568), (9, 529), (10, 511), (3, 392), (0, 321), (1, 233), (2, 225)]\n",
      "bloodmnist\n",
      "[(6, 333), (1, 312), (3, 290), (7, 235), (2, 155), (5, 143), (0, 122), (4, 122)]\n",
      "organsmnist\n",
      "[(6, 491), (9, 280), (8, 275), (7, 261), (3, 246), (10, 213), (0, 188), (5, 159), (4, 140), (1, 104), (2, 95)]\n",
      "dermamnist\n",
      "[(5, 671), (4, 111), (2, 110), (1, 52), (0, 33), (6, 14), (3, 12)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "source_dir = '/mnt/sda/julie/datasets/medmnist/images/'\n",
    "target_dir = '/mnt/sda/julie/projects/OpenMedLongTailed/numpy/medmnist/'\n",
    "for i, dataset in enumerate(os.listdir(source_dir)):\n",
    "    labels = []\n",
    "    train_samples = []\n",
    "    val_samples = []\n",
    "    test_samples = []\n",
    "    dic = {}\n",
    "    dataset_name = dataset.split('_')[0]\n",
    "    print(dataset_name)\n",
    "    images = os.listdir(os.path.join(source_dir, dataset))\n",
    "    for img in images:\n",
    "        if img.startswith('val'):\n",
    "            label = int(img.split('.jpg')[0].split('_')[-1])\n",
    "            labels.append(label)\n",
    "    from collections import Counter\n",
    "    c = Counter(labels).most_common()\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train = np.load('/mnt/sda/julie/projects/OpenMedLongTailed/numpy/medmnist/organsmnist_train.npy')\n",
    "dic = np.load('/mnt/sda/julie/projects/OpenMedLongTailed/numpy/medmnist/organsmnist_dic.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for s in train:\n",
    "    labels.append(dic[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import  Counter\n",
    "c = Counter((labels)).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00028868, 0.000499  , 0.00072516, 0.00114943, 0.00182149,\n",
       "        0.00289017, 0.00456621, 0.00724638, 0.01149425, 0.01818182,\n",
       "        0.02857143]),\n",
       " 0.07743402756709027)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_count = [x[1] for x in c]\n",
    "c, label_to_count\n",
    "per_cls_weights = 1 / np.array(label_to_count)\n",
    "per_cls_weights, sum(per_cls_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.indices = list(range(len(dataset))) \\\n",
    "    if indices is None else indices\n",
    "    \n",
    "# if num_samples is not provided, \n",
    "# draw `len(indices)` samples in each iteration\n",
    "self.num_samples = len(self.indices) \\\n",
    "    if num_samples is None else num_samples\n",
    "    \n",
    "# distribution of classes in the dataset \n",
    "label_to_count = [0] * len(np.unique(dataset.img_label))\n",
    "for idx in self.indices:\n",
    "    label = self._get_label(dataset, idx)\n",
    "    label_to_count[label] += 1\n",
    "\n",
    "\n",
    "# weight for each sample\n",
    "weights = [per_cls_weights[self._get_label(dataset, idx)]\n",
    "           for idx in self.indices]\n",
    "\n",
    "self.per_cls_weights = per_cls_weights\n",
    "self.weights = torch.DoubleTensor(weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
